{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hrishabhsaini18/basic_deep_learning/blob/main/Image_classifier_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "ZuQOkeODGqUj"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "7Ma8aoQyIZIf"
      },
      "outputs": [],
      "source": [
        "# When we have raw images(0,255)RGB, we want those to change to (-1,1)\n",
        "# and want them as tensors before they get fed into the network!\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(), # make it (0,1) also\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) #give (mean) & (std dev) for each RGB channel\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "80dYmNdk38Cx"
      },
      "outputs": [],
      "source": [
        "train_data = torchvision.datasets.CIFAR10(root='./sample_data/', train=True, transform=transform, download=True)\n",
        "test_data = torchvision.datasets.CIFAR10(root='./sample_data/', train=False, transform=transform, download=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=32, shuffle=True, num_workers=2)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=32, shuffle=True, num_workers=2)"
      ],
      "metadata": {
        "id": "TA0t4wa85BH_"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image, label = train_data[0]\n",
        "image.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_wxNMEb5ZUB",
        "outputId": "166231d5-3bc6-4339-fd4b-dd31a1df5815"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 32, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# these are the classes corresponding to the output label number in the classification\n",
        "class_names = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
      ],
      "metadata": {
        "id": "jM2Soq8z55mL"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNNclassifier(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d( 3, 12, 5 ) # (3channels, 12featureMaps, 5FilterSize)  --> gives {(32-5)/stride +1} i.e. (12, 28, 28) size new\n",
        "    self.pool = nn.MaxPool2d(2, 2) # take a 2*2 filter, thus make new size as (12, 14, 14)\n",
        "    self.conv2 = nn.Conv2d(12,24,5) # (12, 14, 14) --> (24, 10, 10) --> MaxPool-> Flatten(24*5*5)\n",
        "    self.fc1 = nn.Linear(24*5*5, 128)\n",
        "    self.fc2 = nn.Linear(128,64)\n",
        "    self.out = nn.Linear(64, 10)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = self.pool(F.relu(self.conv1(x)))\n",
        "    x = self.pool(F.relu(self.conv2(x)))\n",
        "    x = torch.flatten(x, 1)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.out(x)\n",
        "\n",
        "    return x\n",
        ""
      ],
      "metadata": {
        "id": "E6Kev9dk6PrB"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CNNclassifier()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.75)"
      ],
      "metadata": {
        "id": "8N68GFxO-8rR"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecee3695",
        "outputId": "f7aeb9e9-1da7-47a8-a481-502d01c60a7a"
      },
      "source": [
        "# 1. Check for CUDA availability and define the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7d7abb00"
      },
      "source": [
        "# 2. Move your model to the selected device\n",
        "model = CNNclassifier().to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89e85414",
        "outputId": "8c694c69-290b-4db0-db69-06649145d3b0"
      },
      "source": [
        "# 3. In your training loop, move data to the device for each batch\n",
        "epoch = 35\n",
        "\n",
        "for i in range(epoch):\n",
        "  print(f'Training epoch: {i}...')\n",
        "  running_loss = 0.0\n",
        "\n",
        "  for j, data in enumerate(train_loader):\n",
        "    inputs, labels = data\n",
        "    # Move data to the GPU\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    running_loss += loss.item()\n",
        "\n",
        "  print(f'Loss: {running_loss/len(train_loader):.4f}')"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch: 0...\n",
            "Loss: 1.5292\n",
            "Training epoch: 1...\n",
            "Loss: 1.2309\n",
            "Training epoch: 2...\n",
            "Loss: 1.0874\n",
            "Training epoch: 3...\n",
            "Loss: 0.9787\n",
            "Training epoch: 4...\n",
            "Loss: 0.8980\n",
            "Training epoch: 5...\n",
            "Loss: 0.8332\n",
            "Training epoch: 6...\n",
            "Loss: 0.7821\n",
            "Training epoch: 7...\n",
            "Loss: 0.7354\n",
            "Training epoch: 8...\n",
            "Loss: 0.6935\n",
            "Training epoch: 9...\n",
            "Loss: 0.6540\n",
            "Training epoch: 10...\n",
            "Loss: 0.6175\n",
            "Training epoch: 11...\n",
            "Loss: 0.5876\n",
            "Training epoch: 12...\n",
            "Loss: 0.5538\n",
            "Training epoch: 13...\n",
            "Loss: 0.5263\n",
            "Training epoch: 14...\n",
            "Loss: 0.5008\n",
            "Training epoch: 15...\n",
            "Loss: 0.4759\n",
            "Training epoch: 16...\n",
            "Loss: 0.4519\n",
            "Training epoch: 17...\n",
            "Loss: 0.4321\n",
            "Training epoch: 18...\n",
            "Loss: 0.4136\n",
            "Training epoch: 19...\n",
            "Loss: 0.3908\n",
            "Training epoch: 20...\n",
            "Loss: 0.3739\n",
            "Training epoch: 21...\n",
            "Loss: 0.3575\n",
            "Training epoch: 22...\n",
            "Loss: 0.3440\n",
            "Training epoch: 23...\n",
            "Loss: 0.3327\n",
            "Training epoch: 24...\n",
            "Loss: 0.3191\n",
            "Training epoch: 25...\n",
            "Loss: 0.3050\n",
            "Training epoch: 26...\n",
            "Loss: 0.2910\n",
            "Training epoch: 27...\n",
            "Loss: 0.2820\n",
            "Training epoch: 28...\n",
            "Loss: 0.2743\n",
            "Training epoch: 29...\n",
            "Loss: 0.2686\n",
            "Training epoch: 30...\n",
            "Loss: 0.2496\n",
            "Training epoch: 31...\n",
            "Loss: 0.2435\n",
            "Training epoch: 32...\n",
            "Loss: 0.2473\n",
            "Training epoch: 33...\n",
            "Loss: 0.2361\n",
            "Training epoch: 34...\n",
            "Loss: 0.2262\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'trained_net.pth')"
      ],
      "metadata": {
        "id": "QcqXtkM-BWum"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2 = CNNclassifier()\n",
        "model_2.load_state_dict(torch.load('trained_net.pth'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6Aa24gMBpWY",
        "outputId": "762ed2a2-2d9e-4213-ca0b-c685e7266968"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "model_2.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader:\n",
        "    images, labels = data\n",
        "\n",
        "    # Move data to the GPU\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    outputs = model(images)\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    total +=labels.size(0)\n",
        "    correct += (predicted==labels).sum().item()\n",
        "\n",
        "accuracy = 100*(correct/total)\n",
        "print(f'Accuracy:{accuracy}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cuVom-GwB7ap",
        "outputId": "1918d7fd-8a0a-418a-8ad6-da74b6b1b575"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:64.35%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Test images from internet\n",
        "new_transform = transforms.Compose([\n",
        "    transforms.Resize((32,32)), # since our images are not in 32*32, provide size as a tuple\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "])"
      ],
      "metadata": {
        "id": "rBR1ETXeC-6P"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image # Import Image from PIL\n",
        "\n",
        "def load_image(image_path):\n",
        "  image = Image.open(image_path) # Use Image.open\n",
        "  image = new_transform(image)\n",
        "  image = image.unsqueeze(0) # we want to have it like a batch\n",
        "  return image\n",
        "\n",
        "image_path = ['./sample_data/validation_dataset_CNN/image1.jpeg', './sample_data/validation_dataset_CNN/image2.jpeg', './sample_data/validation_dataset_CNN/image3.jpeg', './sample_data/validation_dataset_CNN/image4.jpeg','./sample_data/validation_dataset_CNN/image5.jpeg']\n",
        "images = [load_image(img) for img in image_path]"
      ],
      "metadata": {
        "id": "j7LjRtHrEqPk"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "887ba3a0",
        "outputId": "4aac62ee-595b-4227-9b21-af2f506a8494"
      },
      "source": [
        "model_2.eval()\n",
        "with torch.no_grad():\n",
        "  for image in images:\n",
        "    output = model_2(image)\n",
        "    _, predicted = torch.max(output, 1)\n",
        "    print(f'Prediction:{class_names[predicted.item()]}')"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction:plane\n",
            "Prediction:dog\n",
            "Prediction:dog\n",
            "Prediction:dog\n",
            "Prediction:dog\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOSjHEFZfB4ixvMLgMXTCHW",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}